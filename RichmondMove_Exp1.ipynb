{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Moving To Richmond"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "##!conda install -c anaconda beautifulsoup4 -y\n##!conda install -c anaconda lxml -y\n##!conda install -c anaconda requests -y\n##!conda config --add channels conda-forge\n##!conda install -c conda-forge geopy --yes\n##!conda install -c conda-forge folium=0.5.0 --yes\n##  imports and functions\nfrom project_lib import Project\nfrom bs4 import BeautifulSoup\nimport requests\nimport lxml\nimport csv\nimport pandas as pd\nimport numpy as np\nfrom geopy.geocoders import Nominatim # module to convert an address into latitude and longitude values\nfrom geopy import distance\n# libraries for displaying images\nfrom IPython.display import Image \nfrom IPython.core.display import HTML     \n# tranforming json file into a pandas dataframe library\nfrom pandas.io.json import json_normalize\nimport folium # plotting library\n# Matplotlib and associated plotting modules\nimport matplotlib.cm as cm\nimport matplotlib.colors as colors\nimport matplotlib.pyplot as plt\nimport seaborn as sns\n# import k-means from clustering stage\nfrom sklearn.cluster import KMeans\n\ndef return_most_common_venues(row, num_top_venues):\n    row_categories = row.iloc[1:]\n    row_categories_sorted = row_categories.sort_values(ascending=False)\n    \n    return row_categories_sorted.index.values[0:num_top_venues]\nRVA_Cities =['richmond, va','chesterfield, va', 'midlothian, va', 'henrico, va', 'glen allen, va', 'ashland, va','chmamberlayne, va', 'mechanicsville, va']\nnew_job_addr = '7100 Forest Ave 23226'\nrva_gs = ['Grocery Store', 'Supermarket','Drugstore', 'Pharmacy', 'Market', 'Coffee Shop', 'Wine Shop','Gym / Fitness Center','Salon / Barbershop','Gym','Farmers Market', 'Food & Drink Shop', 'Performing Arts Venue','Museum', 'Theater','Art Museum','Dog Run','Social Club','State / Provincial Park', 'Lake']\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "zipfile = pd.read_csv(\"https://move-econresearch-prod.s3-us-west-2.amazonaws.com/listings/core/current_month/RDC_Inventory_Core_Metrics_Zip_Current.csv\")"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "zip2 = zipfile[['postal_code','zip_name', 'median_listing_price','average_listing_price','new_listing_count','active_listing_count','total_listing_count','price_reduced_count','median_days_on_market']]\n##zip2.head()\nrva_df = zip2.loc[zip2['zip_name'].isin(RVA_Cities)]\nrva_df.rename(columns={'postal_code': 'ZipCode'},inplace=True)\nrva_df"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "##Use geopy library to get the latitude and longitude values of new jobs address\ngeolocator = Nominatim(user_agent=\"my-application\")\nlocation = geolocator.geocode(new_job_addr)\nnja_latitude = location.latitude\nnja_longitude = location.longitude\nprint('The geograpical coordinates of {} are {}, {}.'.format(new_job_addr, nja_latitude, nja_longitude))\nprint(location.raw['display_name'])"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "coords = []\n \ngeolocator = Nominatim(user_agent=\"my-application\")\nfor zipcode, city in zip(rva_df['ZipCode'],rva_df['zip_name'] ):\n    location = geolocator.geocode({\"postalcode\": zipcode, \"state\": 'VA'})\n    latitude2 = location.latitude\n    longitude2 = location.longitude\n    ##print(location)\n    miles = distance.distance((nja_latitude,nja_longitude),(latitude2,longitude2)).mi\n    #print(round(miles))\n    coords.append((\n        zipcode,\n        latitude2,\n        longitude2,\n        miles,\n        location.raw['display_name']))"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# dconvert the list into a new DataFrame\ncoords_df = pd.DataFrame(coords)\n#define the column names\ncoords_df.columns = ['ZipCode','Latitude', 'Longitude', 'Distance','display_name']\n\nprint(coords_df.shape)\ncoords_df.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "mylist = coords_df['display_name'].to_list()\ncleaner = []\nfor row in mylist:\n    x = row.split(',')\n    cleaner.append((x.pop(0)))\ncoords_df['display_name'] = pd.Series(cleaner)\ncoords_df.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {
                "scrolled": true
            },
            "outputs": [],
            "source": "# create map\nmap_zip = folium.Map(location=[nja_latitude, nja_longitude], zoom_start=12)\n\nlabel = '7100 Forest Ave 23226'\nlabel = folium.Popup(label, parse_html=True)\nfolium.CircleMarker(\n    [nja_latitude, nja_longitude],\n    radius=5,\n    popup=label,\n    color='red',\n    fill=True,\n    fill_color='#FDBB84',\n    fill_opacity=0.7).add_to(map_zip)  \n\n \nfor lat, lng, zipcode, dispname in zip(coords_df['Latitude'], coords_df['Longitude'],coords_df['ZipCode'], coords_df['display_name']):\n    label = '{}, {}'.format(dispname, zipcode)\n    label = folium.Popup(label, parse_html=True)\n    folium.CircleMarker(\n        [lat, lng],\n        radius=5,\n        popup=label,\n        color='blue',\n        fill=True,\n        fill_color='#3186cc',\n        fill_opacity=0.7).add_to(map_zip)        \nmap_zip"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# The code was removed by Watson Studio for sharing."
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "##get the area info for goods and services\n## Foursquare API required inputs\nVERSION = '20180604'\nLIMIT = 100\nradius = 5000\nvenue_list = []\n\n##loop thru and get info from 4square\nfor lat, lng, zipcode, dispname in zip(coords_df['Latitude'], coords_df['Longitude'],coords_df['ZipCode'], coords_df['display_name']):\n    url = \"https://api.foursquare.com/v2/venues/explore?client_id={}&client_secret={}&v={}&ll={},{}&radius={}&limit={}\".format(\n        CLIENT_ID,\n        CLIENT_SECRET,\n        VERSION,\n        lat,\n        lng,\n        radius, \n        LIMIT)\n    \n    results = requests.get(url).json()\n\n    items = results['response']['groups'][0]['items']\n    ##print(items)\n    ##break\n    for venue in items:\n        try:\n            venue_list.append(( \n                zipcode,\n                dispname, \n                venue['venue']['name'], \n                venue['venue']['location']['address'],\n                venue['venue']['categories'][0]['name']))\n        except:\n            continue"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "# dconvert the venue list into a new DataFrame\nvenues_df = pd.DataFrame(venue_list)\n#define the column names\nvenues_df.columns = ['ZipCode','Display_Name', 'VenueName', 'VenueAddress', 'Category']\n\nprint(venues_df.shape)\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "print('There are {} uniques categories.'.format(len(venues_df['Category'].unique())))"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "##reduce the number of categories to the ones of interest\nrva_ven = venues_df.loc[venues_df['Category'].isin(rva_gs)]\n##rva_ven.head()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "###group everything up and see what is where\nrva_onehot = pd.get_dummies(rva_ven[['Category']], prefix=\"\", prefix_sep=\"\")\n\n#print one hot totals\nprint( rva_onehot.sum(axis = 0, skipna = True))\n\n# add zipcode and name column back to dataframe\n \nrva_onehot['ZipCode'] = rva_ven['ZipCode'] \n\n\n#  zipcode and displayname column to the first column\nfixed_columns = list(rva_onehot.columns[-2:]) + list(rva_onehot.columns[:-2])\nrva_onehot = rva_onehot[fixed_columns]\n\nprint(\"OneHot Shape: {}\".format(rva_onehot.shape))\nrva_onehot.head()\n\nrva_grouped = rva_onehot.groupby(['ZipCode']).sum().reset_index()\n\nprint(\"Grouped Shape: {}\".format(rva_grouped.shape))\nprint(rva_grouped)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "##of the venues of interest what are we most likely to find in the zipcodea\n\nnum_top_venues = 5\n\nindicators = ['st', 'nd', 'rd']\n\n# create columns according to number of top venues\ncolumns = ['ZipCode']\nfor ind in np.arange(num_top_venues):\n    try:\n        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n    except:\n        columns.append('{}th Most Common Venue'.format(ind+1))\n\n# create a new dataframe\npostcode_venues_sorted = pd.DataFrame(columns=columns)\npostcode_venues_sorted['ZipCode'] = rva_grouped['ZipCode']\n\nfor ind in np.arange(rva_grouped.shape[0]):\n    postcode_venues_sorted.iloc[ind, 1:] = return_most_common_venues(rva_grouped.iloc[ind, :], num_top_venues)\n\npostcode_venues_sorted"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "## compare to most common place of all places\nrva_onehot2 = pd.get_dummies(venues_df[['Category']], prefix=\"\", prefix_sep=\"\")\n\n# add zipcode and displayname column back to dataframe\n \nrva_onehot2['ZipCode'] = venues_df['ZipCode'] \nrva_onehot2['Display_Name'] = venues_df['Display_Name']\n\n#  zipcode and displayname column to the first column\nfixed_columns = list(rva_onehot2.columns[-2:]) + list(rva_onehot2.columns[:-2])\nrva_onehot2 = rva_onehot2[fixed_columns]\n\nprint(rva_onehot2.shape)\nrva_onehot2.head()\n\nrva_grouped2 = rva_onehot2.groupby(['ZipCode']).sum().reset_index()\n\nnum_top_venues = 5\n\nindicators = ['st', 'nd', 'rd']\n\n# create columns according to number of top venues\ncolumns = ['ZipCode']\nfor ind in np.arange(num_top_venues):\n    try:\n        columns.append('{}{} Most Common Venue'.format(ind+1, indicators[ind]))\n    except:\n        columns.append('{}th Most Common Venue'.format(ind+1))\n\n# create a new dataframe\npostcode_venues_sorted = pd.DataFrame(columns=columns)\npostcode_venues_sorted['ZipCode'] = rva_grouped2['ZipCode']\n\nfor ind in np.arange(rva_grouped2.shape[0]):\n    postcode_venues_sorted.iloc[ind, 1:] = return_most_common_venues(rva_grouped2.iloc[ind, :], num_top_venues)\n\npostcode_venues_sorted"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "#Now lets look at the real estate \nrva_df.corr()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "sns.regplot(x=\"median_listing_price\", y=\"median_days_on_market\", data=rva_df)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "sns.regplot(x=\"price_reduced_count\", y=\"median_days_on_market\", data=rva_df)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "sns.regplot(x=\"price_reduced_count\", y=\"active_listing_count\", data=rva_df)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "rva_merged = pd.merge(rva_df, rva_grouped, how='left',\n        on='ZipCode', validate=\"1:1\")\nrva_merged.head()\n##write results to csv to import into excel or other uses for later\nproject.save_data(file_name = \"merged_data.csv\",data = rva_merged.to_csv(index=False))\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "rva_merged.corr()"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": "sns.regplot(x=\"average_listing_price\", y=\"Coffee Shop\", data=rva_merged)"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.8"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}